{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-16T00:47:10.347233Z","iopub.status.busy":"2023-04-16T00:47:10.346813Z","iopub.status.idle":"2023-04-16T00:47:11.186688Z","shell.execute_reply":"2023-04-16T00:47:11.185411Z","shell.execute_reply.started":"2023-04-16T00:47:10.347196Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import re\n","import string\n","import nltk\n","\n","df = pd.read_csv('/kaggle/input/patient/dataset.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-16T00:47:14.684917Z","iopub.status.busy":"2023-04-16T00:47:14.684490Z","iopub.status.idle":"2023-04-16T00:47:14.890638Z","shell.execute_reply":"2023-04-16T00:47:14.889284Z","shell.execute_reply.started":"2023-04-16T00:47:14.684877Z"},"trusted":true},"outputs":[],"source":["df.isnull().sum()\n","df = df.fillna(0)\n","df = df.dropna(axis=1, how='all')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-16T00:47:17.659385Z","iopub.status.busy":"2023-04-16T00:47:17.658027Z","iopub.status.idle":"2023-04-16T00:47:17.667149Z","shell.execute_reply":"2023-04-16T00:47:17.665843Z","shell.execute_reply.started":"2023-04-16T00:47:17.659320Z"},"trusted":true},"outputs":[],"source":["print(df.columns)\n","print(len(df.columns))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-16T00:47:20.662294Z","iopub.status.busy":"2023-04-16T00:47:20.661701Z","iopub.status.idle":"2023-04-16T00:47:20.700454Z","shell.execute_reply":"2023-04-16T00:47:20.698933Z","shell.execute_reply.started":"2023-04-16T00:47:20.662241Z"},"trusted":true},"outputs":[],"source":["df.drop(['Unnamed: 83'],  axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-16T00:47:24.142966Z","iopub.status.busy":"2023-04-16T00:47:24.142513Z","iopub.status.idle":"2023-04-16T00:47:24.370506Z","shell.execute_reply":"2023-04-16T00:47:24.369127Z","shell.execute_reply.started":"2023-04-16T00:47:24.142925Z"},"trusted":true},"outputs":[],"source":["# one hot encode the categorical variables\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","import pandas as pd\n","\n","dummies = pd.get_dummies(df[['icu_admit_source', 'ethnicity', 'gender', 'icu_type', 'apache_3j_bodysystem', 'apache_2_bodysystem', 'icu_stay_type']])\n","# concatenate the one-hot encoded columns with the original DataFrame\n","df = pd.concat([df, dummies], axis=1)\n","# drop the original categorical columns\n","df.drop(['icu_admit_source', 'ethnicity', 'gender', 'icu_type', 'apache_3j_bodysystem', 'apache_2_bodysystem', 'icu_stay_type'], axis=1, inplace=True)\n","print(df.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# manually drop irrelevant columns\n","df.drop(['patient_id'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# univariate data analysis\n","\n","import pandas as pd\n","import seaborn as sns\n","\n","# perform univariate analysis\n","# summary statistics\n","print(df.describe())\n","\n","# histogram\n","df.hist()\n","\n","# kernel density plot\n","df.plot(kind='density')\n","\n","# box plot\n","df.plot(kind='box')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T16:26:15.098161Z","iopub.status.busy":"2023-04-15T16:26:15.097723Z","iopub.status.idle":"2023-04-15T16:27:12.901944Z","shell.execute_reply":"2023-04-15T16:27:12.899938Z","shell.execute_reply.started":"2023-04-15T16:26:15.098119Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(20,20))\n","sns.heatmap(df.corr(), annot=True, fmt='.0%')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T16:27:56.391907Z","iopub.status.busy":"2023-04-15T16:27:56.391324Z","iopub.status.idle":"2023-04-15T16:28:00.691371Z","shell.execute_reply":"2023-04-15T16:28:00.690008Z","shell.execute_reply.started":"2023-04-15T16:27:56.391855Z"},"trusted":true},"outputs":[],"source":["# correlation and feature removal\n","\n","import pandas as pd\n","\n","# Find correlation matrix\n","corr_matrix = df.corr().abs()\n","# Set threshold for correlation coefficient\n","threshold = 0.85\n","\n","# copy df into dropped_df\n","dropped_df = df.copy()\n","# Find features with correlation greater than threshold\n","high_corr_features = set()\n","for i in range(len(corr_matrix.columns)):\n","    for j in range(i):\n","        if corr_matrix.iloc[i, j] >= threshold:\n","            colname_i = corr_matrix.columns[i]\n","            colname_j = corr_matrix.columns[j]\n","            if colname_i not in high_corr_features:\n","                high_corr_features.add(colname_j)\n","\n","# Remove highly correlated features from DataFrame\n","dropped_df.drop(high_corr_features, axis=1, inplace=True)\n","print(len(dropped_df.columns))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T16:28:13.633783Z","iopub.status.busy":"2023-04-15T16:28:13.633299Z","iopub.status.idle":"2023-04-15T16:28:14.031240Z","shell.execute_reply":"2023-04-15T16:28:14.029814Z","shell.execute_reply.started":"2023-04-15T16:28:13.633742Z"},"trusted":true},"outputs":[],"source":["# removing outliers using z-score\n","import pandas as pd\n","from scipy.stats import zscore\n","\n","# Calculate z-scores for each feature\n","z_scores = df.apply(zscore)\n","\n","# # Identify outliers by setting a threshold for z-score\n","threshold = 3\n","outliers = (z_scores > threshold).any(axis=1)\n","\n","# # Remove outliers from DataFrame\n","df_outliers_removed = df[~outliers]\n","print(df_outliers_removed.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T16:28:23.513732Z","iopub.status.busy":"2023-04-15T16:28:23.513209Z","iopub.status.idle":"2023-04-15T16:28:34.820923Z","shell.execute_reply":"2023-04-15T16:28:34.819301Z","shell.execute_reply.started":"2023-04-15T16:28:23.513687Z"},"trusted":true},"outputs":[],"source":["from sklearn.feature_selection import f_classif\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","\n","# set the target variable column name\n","target_col = 'hospital_death'\n","\n","# split the data into training and testing sets\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# initialize the list of selected features\n","selected_features = []\n","\n","# create a copy of the training set to keep track of the remaining features\n","remaining_features = train_df.columns.drop(target_col)\n","\n","# iterate over the remaining features and select the one that has the highest F-value\n","while len(remaining_features) > 0:\n","    f_values, p_values = f_classif(train_df[remaining_features], train_df[target_col])\n","    best_feature_index = np.argmax(f_values)\n","    best_feature = remaining_features[best_feature_index]\n","    \n","    # add the best feature to the list of selected features and remove it from the remaining features\n","    selected_features.append(best_feature)\n","    remaining_features = remaining_features.drop(best_feature)\n","    \n","    # print the selected feature and its corresponding F-value\n","    # print('Selected feature:', best_feature, 'with F-value:', f_values[best_feature_index])\n","\n","# create a new DataFrame with the selected features\n","forward_selected_df = train_df[selected_features + [target_col]]\n","\n","# display the selected features\n","print('Selected features:', selected_features)"]},{"cell_type":"markdown","metadata":{},"source":["Include PCA"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.decomposition import PCA\n","import numpy as np\n","\n","# Create a sample dataset with 4 features and 100 samples\n","X = np.random.rand(100, 4)\n","\n","# Instantiate a PCA object with 2 components\n","pca = PCA(n_components=2)\n","\n","# Fit the PCA model to the data\n","pca.fit(X)\n","\n","# Transform the data to the new coordinate system\n","X_transformed = pca.transform(X)\n","\n","# Print the explained variance ratio of each principal component\n","print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n","\n","# Print the transformed data\n","print(\"Transformed data:\", X_transformed)"]},{"cell_type":"markdown","metadata":{},"source":["# Modeling\n","\n","- Random forest\n","- XGBoost\n","- Catboost \n","- Decision Trees\n","- Stacking \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
